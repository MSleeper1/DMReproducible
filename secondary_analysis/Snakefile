#!/usr/bin/env snakemake --cluster-config ../cluster.yaml --cluster "sbatch --parsable --time={cluster.time} --mem={cluster.mem_mb} --nodes={cluster.nodes} --cpus-per-task={cluster.cpus-per-task} --output={cluster.output} --error={cluster.error} --job-name={cluster.name}" --jobs 20 --use-conda --rerun-incomplete --printshellcmds

#### snakemake secondary analysis subworkflow pipeline ####
# author: Meghan M. Sleeper
# run on farm cluster with:  snakemake --cluster-config ../cluster.yaml --cluster "sbatch --parsable --time={cluster.time} --mem={cluster.mem_mb} --nodes={cluster.nodes} --cpus-per-task={cluster.cpus-per-task} --output={cluster.output} --error={cluster.error} --job-name={cluster.name}" --jobs 20 --use-conda --rerun-incomplete --printshellcmds --rerun-triggers mtime --dry-run
# runs as a subworkflow for the DMReproducible pipeline
# purpose:
#    - to map and call methylation data from fastq files
#    - to run quality control on fastq files
#    - to annotate methylation data
#    - to run differential methylation analysis
# input: 
#    - tsv file specifying data accession numbers and associated metadata for wgbs data on SRA
#    - config file specifying reference genome and file paths
# output: 
#    - beta values for methylation data
#    - quality control reports
#    - differential methylation analysis results
#    - methylation data annotations
# overview of secondary analysis steps:
#    - map fastq files to reference genome
#    - call methylation data from mapped files
#    - run quality control on fastq files
#    - combine methylation data from multiple samples
#    - annotate methylation data

#### import modules ####
import pandas as pd
import secondary_helper_functions as hf

#### assign config ####
configfile: "../config.yaml"

#### sample info ####
sample_info = hf.get_sample_info_df(config["root"] + "/" + config["samples_tsv"])
sample_info_se = sample_info[sample_info['layout'] == 'se']
sample_info_pe = sample_info[sample_info['layout'] == 'pe']

#### set up conditional files for rule all input ####
rule_all_input_list = [
    expand("{data_dir}/06_wgbstools_betas/{sample.ref}-{sample.patient_id}-{sample.group}-{sample.srx_id}-{sample.layout}_merged.{suf}", data_dir=config["data_dir"], suf=["pat.gz", "pat.gz.csi", "beta"], sample=sample_info.itertuples()),
    expand("{root}/{data_dir}/01_raw_sequence_files/{se.ref}--{se.patient_id}-{se.group}-{se.srx_id}-{se.layout}/{se.accession}.fastq", root = config["root"], data_dir=config["data_dir"], se=sample_info_se.itertuples()), # sra_get_data se output
    expand("{root}/{data_dir}/01_raw_sequence_files/{pe.ref}--{pe.patient_id}-{pe.group}-{pe.srx_id}-{pe.layout}/{pe.accession}{suf}", root = config["root"], data_dir=config["data_dir"], pe=sample_info_pe.itertuples(), suf={"_1.fastq", "_2.fastq"}), # sra_get_data pe R1 and R2 output
    ]

if config["bismark"] == False:
    rule_all_input_list.remove(expand("{root}/{genomes_dir}/{genome}/bismark/Bisulfite_Genome/", root = config["root"], genomes_dir = config["genomes_dir"], genome = config["ref"]["genome"]))

# rule_all_input_list = [
#      expand("{data_dir}/06_wgbstools_betas/{sample.ref}-{sample.patient_id}-{sample.group}-{sample.srx_id}-{sample.layout}_merged.{suf}", data_dir=config["data_dir"], suf=["pat.gz", "pat.gz.csi", "beta"], sample=sample_info.itertuples()), 
#      expand("{rep_dir}/summary/01-06_bis_multiqc.html", rep_dir=config["reports_dir"]), 
#      expand("{rep_dir}/summary/01-06_bwa_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/01_raw_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/02_trimmed_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/03_bwameth_mapping_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/03_bismark_mapping_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/04_bwa_deduped_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/04_bis_deduped_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/05_bwa_post_merge_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/05_bis_post_merge_multiqc.html", rep_dir=config["reports_dir"]),
#      expand("{rep_dir}/summary/06_bis_methyl_extract_multiqc.html", rep_dir=config["reports_dir"])
#      ]

# if config["bismark"] == False:
#      rule_all_input_list.remove(expand("{rep_dir}/summary/01-06_bis_multiqc.html", rep_dir=config["reports_dir"]))
#      rule_all_input_list.remove(expand("{rep_dir}/summary/03_bismark_mapping_multiqc.html", rep_dir=config["reports_dir"]))
#      rule_all_input_list.remove(expand("{rep_dir}/summary/04_bis_deduped_multiqc.html", rep_dir=config["reports_dir"]))
#      rule_all_input_list.remove(expand("{rep_dir}/summary/05_bis_post_merge_multiqc.html", rep_dir=config["reports_dir"]))
#      rule_all_input_list.remove(expand("{rep_dir}/summary/06_bis_methyl_extract_multiqc.html", rep_dir=config["reports_dir"]))

# if config["sra_download"] == False:
#     rule_all_input_list.remove(expand("{root}/{data_dir}/01_raw_sequence_files/{se.ref}--{se.patient_id}-{se.group}-{se.srx_id}-{se.layout}/{se.accession}.fastq", root = config["root"], data_dir=config["data_dir"], se=sample_info_se.itertuples())), 
#     rule_all_input_list.remove(expand("{root}/{data_dir}/01_raw_sequence_files/{pe.ref}--{pe.patient_id}-{pe.group}-{pe.srx_id}-{pe.layout}/{pe.accession}{suf}", root = config["root"], data_dir=config["data_dir"], pe=sample_info_pe.itertuples(), suf={"_1.fastq", "_2.fastq"}))

#### default rule ####
rule all:
     input:
          rule_all_input_list


##### include rules #####
include: "rules/get_ref.smk"
include: "rules/get_samples.smk"
include: "rules/ref_index_bismark.smk"
include: "rules/ref_index_bwameth.smk"
include: "rules/ref_init_wgbstools.smk"
include: "rules/ref_prep_fastqscreen.smk"


#### -- Intermediate files produced by prep-Snakefile that could be added to rule all -- ###

# Must uncomment these lines to include these intermediate files in the rule all
# sample_info_se = sample_info[sample_info['layout'] == 'se']
# sample_info_pe = sample_info[sample_info['layout'] == 'pe']

        #   ### 00 reference genome file prep ###
        #   expand("{ref_dir}/{fasta}.fa.gz", ref_dir=config["ref"]["dir"], fasta=config["ref"]["fasta"]),  # rsync_get_ref_genome output
        #   expand("{ref_dir}/{fasta}.fa", ref_dir=config["ref"]["dir"], fasta=config["ref"]["fasta"]),  # rsync_get_ref_genome unzipped output
        #   expand("{bwa_idx_dir}/{fasta}.fa.gz.bwameth.{suf}", suf=["c2t", "c2t.bwt", "c2t.pac", "c2t.ann", "c2t.amb", "c2t.sa"], bwa_idx_dir=config["ref"]["bwa_idx_dir"], fasta=config["ref"]["fasta"]), # bwameth_index_ref output
        #   expand("{bismark_idx_dir}", bismark_idx_dir=config["ref"]["bismark_idx_dir"]),  # bismark_index_ref output
        #   expand("{wgbstools_ref_dir}/{genome}", wgbstools_ref_dir=config["ref"]["wgbstools_idx_dir"], genome=config["ref"]["wgbstools_ref_name"]),  # wgbstools_init_ref output
        #   expand("{genomes_dir}/FastQ_Screen_Genomes_Bisulfite/", genomes_dir=config["genomes_dir"]),
        #   expand("{genomes_dir}/FastQ_Screen_Genomes_Bisulfite/fastq_screen.conf", genomes_dir=config["genomes_dir"]),
        #   expand("{ref_dir}/{gtf}.{suf}", ref_dir = config["ref"]["dir"], gtf = config["ref"]["gtf"], suf = ["gtf.gz", "gtf"]), # gtf file for ref genome
          
          # ### 01 sra_get_data raw sequence fastq outputs ###
          # expand("{data_dir}/01_raw_sequence_files/{se.ref}/{se.patient_id}-{se.group}-{se.srx_id}-{se.layout}/{se.accession}.fastq", data_dir=config["data_dir"], se=sample_info_se.itertuples()), # sra_get_data se output
          # expand("{data_dir}/01_raw_sequence_files/{pe.ref}/{pe.patient_id}-{pe.group}-{pe.srx_id}-{pe.layout}/{pe.accession}{suf}", data_dir=config["data_dir"], pe=sample_info_pe.itertuples(), suf={"_1.fastq", "_2.fastq"}), # sra_get_data pe R1 and R2 output
          

onsuccess:
    print("Workflow finished, no error")

onerror:
    print("An error occurred")


